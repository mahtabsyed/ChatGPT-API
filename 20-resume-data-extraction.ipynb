{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Data Extraction\n",
    "Very valuable and easy to do\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "# print(openai.api_key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using OpenAI library version 1.0.0, here is the code\n",
    "# openai==1.0.0\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_1 = \"\"\" \n",
    "Mahtab Syed\n",
    "IT Leader | Consulting, Solutions, Program, Technology and People | Deliver Data Engineering, Machine Learning / Artificial Intelligence and MLOps Programs | On Cloud (Azure, AWS) | Generative AI | Love Coding and Kaggle\n",
    "Australian Citizen | 0487031011 | mahtab.syed@gmail.com | https://au.linkedin.com/in/mahtabsyed \n",
    "\n",
    "Career Summary\n",
    "IT Leader with 20 years’ global experience, delivering complex Technical and Business critical programs, using on-premises and cloud technologies (Azure and AWS), solving Business problems, and contributing to Revenue generation.\n",
    "Responsible for Stakeholder Engagement and Delivery (Engineering and Program Teams) for Product and Client Delivery of Azure Data Engineering, Machine Learning and Artificial Intelligence solutions\n",
    "People Leader for mid-sized cross functional teams of Senior Engineers, Principal Engineers, Data Scientists, Business Analysts, Project, and Program Managers and PMO. \n",
    "Code full stack on Machine Learning and Web programming. Github - https://github.com/mahtabsyed Blog and attend industry events on Machine Learning - https://www.linkedin.com/in/mahtabsyed/ \n",
    "Computer Science education and managed mission critical Programs in global startups and banks in Seattle, New York, Paris, and Melbourne. Have partnered with Global startup and industry groups. \n",
    "Skills\n",
    "-\tIT Strategy, Organizational Strategy, Data Strategy, Data Governance, Transformation, Capability\n",
    "-\tData Governance (Data Catalog, Metadata, Master Data Management, Data Lineage, Data Accountability, Data Lifecycle Management, Data Ethics and Privacy)\n",
    "-\tLeadership of high-performance teams, Coaching and Mentoring teams\n",
    "-\tPeople Management, Workforce planning, Hiring, Career Development, Capacity allocation, Performance Management, Career Paths, Promotion, Salary and Bonus allocation\n",
    "-\tPMI PMP Certified, Planning, Scope, Cost, Time, Risk Management\n",
    "-\tCertified AWS Solution Architect Associate, On-premises to Cloud Transition\n",
    "-\tData Engineering and Analytics for Business decisions / Regulatory reports\n",
    "-\tBusiness Partner, IT Transformation, Bridging Business needs and IT Solutions\n",
    "-\tKey Stakeholder Management, Executive Communication\n",
    "\n",
    "Technology\n",
    "-\tAzure and AWS Solutions, Engineering and DevOps \n",
    "-\tData Engineering using Cloud on Azure and on-premises using Data Warehouses\n",
    "-\tData Analytics using SQL, Python, Pandas, NumPy and matplotlib\n",
    "-\tMachine Learning and Artificial Intelligence (AI) using Scikit-learn, TensorFlow and PyTorch\n",
    "-\tData Visualization using matplotlib (scientific data), Power BI and Tableau\n",
    "-\tEnterprise Architecture, Design, Full Stack Developer, Master Data Management (MDM) Practices\n",
    "-\tObject Oriented Programming, Service Oriented Architecture (SOA), Java and .NET Framework\n",
    "-\tPython, C++, Java, SQL and RDMBS and No SQL Database \n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Name\": \"Mahtab Syed\",\n",
      "  \"Email\": \"mahtab.syed@gmail.com\",\n",
      "  \"Phone\": \"0487031011\",\n",
      "  \"Summary\": \"IT Leader with 20 years’ global experience, delivering complex Technical and Business critical programs\",\n",
      "  \"Skills\": \"IT Strategy, Organizational Strategy, Data Strategy, Data Governance, Transformation, Capability, Leadership of high-performance teams, Coaching and Mentoring teams, People Management, Workforce planning, Hiring, Career Development, Capacity allocation, Performance Management, Career Paths, Promotion, Salary and Bonus allocation, PMI PMP Certified, Planning, Scope, Cost, Time, Risk Management, Certified AWS Solution Architect Associate, On-premises to Cloud Transition, Data Engineering and Analytics for Business decisions / Regulatory reports, Business Partner, IT Transformation, Bridging Business needs and IT Solutions, Key Stakeholder Management, Executive Communication\",\n",
      "  \"Technology\": \"Azure and AWS Solutions, Engineering and DevOps, Data Engineering using Cloud on Azure and on-premises using Data Warehouses, Data Analytics using SQL, Python, Pandas, NumPy and matplotlib, Machine Learning and Artificial Intelligence (AI) using Scikit-learn, TensorFlow and PyTorch, Data Visualization using matplotlib (scientific data), Power BI and Tableau, Enterprise Architecture, Design, Full Stack Developer, Master Data Management (MDM) Practices, Object Oriented Programming, Service Oriented Architecture (SOA), Java and .NET Framework, Python, C++, Java, SQL and RDMBS and No SQL Database\",\n",
      "  \"Seniority\": \"20\",\n",
      "  \"AI Knowledge\": \"Yes\",\n",
      "  \"Full stack developer\": \"Yes\",\n",
      "  \"Team Management\": \"Yes\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the Resume text: \n",
    "- Name\n",
    "- Email\n",
    "- Phone remove any white spaces\n",
    "- Summary in less than 20 words\n",
    "- Skills\n",
    "- Technology\n",
    "- Seniority as number of years of experience\n",
    "- AI Knowledge as Yes oer No\n",
    "- Full stack developer as Yes or No\n",
    "- Team Manageemnt as Yes or No\n",
    "\n",
    "The Resume is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Name\", \"Email\", \"Phone\", \"Summary\", \"Skills\", \"Technology\", \"Seniority\" as the keys. \\\n",
    "For multiple values use comma separated values \\\n",
    "Remove hyphen, tab and new line characters \\\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "  \n",
    "Resume text: '''{resume_1}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdesc_1 = \"\"\"\n",
    "Job Description\n",
    "\n",
    "ABC Inc. is seeking a highly skilled and experienced AI & Data Architect or Lead to join our Technology Services team in Melbourne, Australia. \n",
    "The ideal candidate will have a deep understanding of both artificial intelligence and data architecture, with a proven track record of designing and implementing scalable, efficient, and robust solutions. \n",
    "The role involves leading the development and execution of our organisation's AI and data strategy, ensuring alignment with business goals and industry best practices. \n",
    "This role entails playing a pivotal part in expanding our AI capabilities, so a mix of strategic, and tactical skills is highly desirable.\n",
    "\n",
    "To Be Successful In This Role You Will Have\n",
    "•\tBachelor's or Master's degree in Computer Science, Data Science, Engineering or a related field.\n",
    "•\tProven experience (15-20 years) in AI and data architecture roles, with a focus on designing and implementing scalable solutions.\n",
    "•\tSolid background in machine learning with experience in large-scale training and deployment of deep neural nets and/or transformer architectures.\n",
    "•\tUpto 5 years of experience with AI based solutions, Predictive Modeling, Advance Analytics, machine learning based solutions, and semantic search technologies.\n",
    "•\tMinimum 3 years of experience in building, scaling, and optimising training and inferencing systems for deep neural networks.\n",
    "•\tStrong expertise in machine learning, data modelling, and data visualisation.\n",
    "•\tProficiency in programming languages such as Python, R, or Java.\n",
    "•\tExperience with big data technologies (e.g., Hadoop, Spark) and cloud platforms (e.g., AWS, Azure, GCP).\n",
    "•\tExcellent leadership and communication skills.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Extract key skills and match:\n",
      "- AI & Data Architecture\n",
      "- Designing and implementing scalable solutions\n",
      "- Machine learning\n",
      "- Deep neural nets and/or transformer architectures\n",
      "- AI based solutions\n",
      "- Predictive Modeling\n",
      "- Advance Analytics\n",
      "- Semantic search technologies\n",
      "- Data modeling\n",
      "- Data visualization\n",
      "- Programming languages: Python, R, Java\n",
      "- Big data technologies: Hadoop, Spark\n",
      "- Cloud platforms: AWS, Azure\n",
      "\n",
      "Step 2 - Summarize and match:\n",
      "The candidate's resume aligns well with the job description as they have extensive experience in IT leadership, data engineering, machine learning, and artificial intelligence. They have worked with Azure and AWS, have experience in data governance, and have managed complex technical programs. The candidate also has experience in leadership, coaching, and mentoring teams, which aligns with the requirement for excellent leadership skills in the job description. Additionally, the candidate's proficiency in programming languages and experience with big data technologies and cloud platforms matches the job requirements.\n",
      "\n",
      "Step 3 - Identify key success factors and match:\n",
      "The candidate's extensive experience in IT leadership, data engineering, machine learning, and artificial intelligence, along with their skills in data governance, leadership, and proficiency in programming languages, make them a strong match for the AI & Data Architect or Lead position at ABC Inc. Their experience in managing complex technical programs and working with cloud platforms aligns well with the job requirements. Additionally, their background in coaching and mentoring teams and their expertise in data modeling and visualization make them a valuable candidate for the role.\n",
      "\n",
      "Overall rating: 90/100 - Excellent match\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Can you rate how well this Resume in '''{resume_1}''' matches with this Job description in ####{jobdesc_1}#### \\\n",
    "in scale of 1 to 100 where 1 is no match (negative), 50 is ok match (neutral) and 100 is excellent match (positive).\\\n",
    "You can follow these steps:\\\n",
    "Step 1 - Extract key skills and match\\\n",
    "Step 2 - Summarize and match\\\n",
    "Step 3 - Identify key success factors and match\\\n",
    "\n",
    "The Resume is delimited with triple ''' \\\n",
    "The Job Description is delimited with #### \\\n",
    "  \n",
    "Resume text: '''{resume_1}''' \\\n",
    "Job description: ####{jobdesc_1}####  \\\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_1 = \"\"\" \n",
    "\n",
    "Mahtab Syed\n",
    "IT Leader | Consulting, Solutions, Program, Technology and People | Deliver Data Engineering, Machine Learning / Artificial Intelligence and MLOps Programs | On Cloud (Azure, AWS) | Generative AI | Love Coding and Kaggle\n",
    "Australian Citizen | 0487031011 | mahtab.syed@gmail.com | https://au.linkedin.com/in/mahtabsyed \n",
    "Career path – Head of Data and AI -> Chief Data Officer\n",
    "\n",
    "Career Summary\n",
    "IT Leader with 20 years’ global experience, delivering complex Technical and Business critical programs, using on-premises and cloud technologies (Azure and AWS), solving Business problems, and contributing to Revenue generation.\n",
    "Responsible for Stakeholder Engagement and Delivery (Engineering and Program Teams) for Product and Client Delivery of Azure Data Engineering, Machine Learning and Artificial Intelligence solutions\n",
    "People Leader for mid-sized cross functional teams of Senior Engineers, Principal Engineers, Data Scientists, Business Analysts, Project, and Program Managers and PMO. \n",
    "Code full stack on Machine Learning and Web programming. Github - https://github.com/mahtabsyed Blog and attend industry events on Machine Learning - https://www.linkedin.com/in/mahtabsyed/ \n",
    "Computer Science education and managed mission critical Programs in global startups and banks in Seattle, New York, Paris, and Melbourne. Have partnered with Global startup and industry groups. \n",
    "Skills\n",
    "-\tIT Strategy, Organizational Strategy, Data Strategy, Data Governance, Transformation, Capability\n",
    "-\tData Governance (Data Catalog, Metadata, Master Data Management, Data Lineage, Data Accountability, Data Lifecycle Management, Data Ethics and Privacy)\n",
    "-\tLeadership of high-performance teams, Coaching and Mentoring teams\n",
    "-\tPeople Management, Workforce planning, Hiring, Career Development, Capacity allocation, Performance Management, Career Paths, Promotion, Salary and Bonus allocation\n",
    "-\tPMI PMP Certified, Planning, Scope, Cost, Time, Risk Management\n",
    "-\tCertified AWS Solution Architect Associate, On-premises to Cloud Transition\n",
    "-\tData Engineering and Analytics for Business decisions / Regulatory reports\n",
    "-\tBusiness Partner, IT Transformation, Bridging Business needs and IT Solutions\n",
    "-\tKey Stakeholder Management, Executive Communication\n",
    "\n",
    "Technology\n",
    "-\tAzure and AWS Solutions, Engineering and DevOps \n",
    "-\tData Engineering using Cloud on Azure and on-premises using Data Warehouses\n",
    "-\tData Analytics using SQL, Python, Pandas, NumPy and matplotlib\n",
    "-\tMachine Learning and Artificial Intelligence (AI) using Scikit-learn, TensorFlow and PyTorch\n",
    "-\tData Visualization using matplotlib (scientific data), Power BI and Tableau\n",
    "-\tEnterprise Architecture, Design, Full Stack Developer, Master Data Management (MDM) Practices\n",
    "-\tObject Oriented Programming, Service Oriented Architecture (SOA), Java and .NET Framework\n",
    "-\tPython, C++, Java, SQL and RDMBS and No SQL Database \n",
    "\n",
    "Methodologies\n",
    "-\tAgile Scrum and Kanban (>10 yrs. Experience), SAFe Agile\n",
    "-\tRapid – For quick results for Business, Waterfall Traditional\n",
    " \n",
    "Education\n",
    "1991 - 1997, Integrated Master of Technology in Computer Science, Odessa State University, Ukraine\n",
    "\n",
    "Experience\n",
    "\n",
    "LAB3 - Data, Machine Learning and Artificial Intelligence - Technology and Delivery\n",
    "Dec 2021 – Till date\n",
    "Melbourne\n",
    "Responsible for Delivery, Program, Technology, Revenue People (Engineering and Project Teams) for Design and Development of Azure Data Engineering, Data Science, Machine Learning and Artificial Intelligence programs. Leading a team of ~30 Senior Engineers and Principals.\n",
    "\n",
    "Projects are for the end-to-end Data and AI offerings of Data Assessment, Data Architecture, Data Platforms, Data Migration, Data Engineering, Data Science and Machine Learning, Machine Learning Operations (MLOps), Artificial Intelligence (Cognitive AI, OpenAI), Reporting and Visualization, Applications and Integration.\n",
    "\n",
    "\n",
    "MCRI – Data and Artificial Intelligence Program - Technology and Delivery\n",
    "Oct 2020 – Dec 2021\n",
    "Melbourne\n",
    "Delivered the Data Infrastructure, Data Repositories and Applications for the GenV Program in Victoria, Australia. Leading a Team of Data Scientists to deliver Machine Learning Use Cases in Azure \n",
    "\n",
    "Led Data Innovation Management Program and Data Science Program \n",
    "1.\tManaged Delivery by controlling levers of Scope, Cost, Time, Quality, Risks, Issues, Dependencies via Program Governance, Responsible for Delivery, Budget, Vendor and Statement of Works. And team leadership and hiring.\n",
    "2.\tLed a team of Data Scientists researching, coding and prototyping and choosing from latest Artificial Intelligence services (AWS Textract and AWS Comprehend, Azure Form Recognizer) and writing Machine Learning models using Neural networks Deep Learning. \n",
    "\n",
    "\n",
    "NAB Bank – Program Manager\n",
    "May 2018 – Apr 2020\n",
    "Melbourne\n",
    "Led 75-member technology and program team to deliver Regulatory Global Tax Fraud Prevention program over 2 yrs and a budget of AUD~65MN and started work on Credit Risk Engine creation.\n",
    "\n",
    "Key achievements are controlling Scope and timely delivery for the Regulatory Program with large scale enterprise Data Engineering, SAS Analytics, and re-architecting from on-premises to AWS cloud native solution.\n",
    "1.\tOECD Common Reporting Standards Business and IT teams\n",
    "In Phase 1 the Program involves Data Transfer across the bank's front office to Enterprise Data warehouse to SAS solution for analytics.  In Phase 2 AWS Cloud was setup for end-to-end data sourcing and analytics.\n",
    "Platform and Technologies - All channels of customer on-boarding, Data warehouses, SAS Analytics, XML Reporting\n",
    "2.\tStarted Credit Risk Calculation Engine development team to meet APRA Basel III Obligations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANZ Bank – Program Director\n",
    "Jul 2017 – Mar 2018\n",
    "Melbourne\n",
    "Program Director responsible for Business and IT teams developing CreditLens application which does Financial Data Extraction, Financial Analysis, Entities and Hierarchy Management and the core function of Risk Grading for Institutional, Commercial and Corporate and Private Banking. \n",
    "This is the single enterprise application, approved by APRA (Australian Prudential Regulation Authority) for Risk Grading application, used globally in ANZ.\n",
    "\n",
    "Bendigo and Adelaide Bank – Technical Project Manager\n",
    "May 2016 – Jul 2017\n",
    "Adelaide and Melbourne\n",
    "\n",
    "Led Architecture, Design Development and Delivery of Business applications for: \n",
    "- Better Credit Decisions (Decision Engine and Interfacing with VEDA / Equifax for Comprehensive Credit Reporting)\n",
    "- Anti Money Laundering / Counter Terrorism Financing (AML / CTF) and Sanctions with PEP Screening solution using BAE NetReveal \n",
    "- e-Conveyancing Solution (PEXA Payments Transformation Program - payments between Conveyancers, Financial institutions, Land Registries and the Reserve Bank of Australia (RBA))\n",
    "\n",
    "Société Générale – IT Head\n",
    "Jun 2013 – Jan 2016\n",
    "Paris and Bangalore\n",
    "Responsible for setting up new IT team for Risk and Finance Technology of Business Solution Centre. Grew this team from 5 members to 120 in 2.5 years, transitioning existing applications and setting up new teams as well, in the area of Liquidity Risk, Credit Risk, Anti Money Laundering, Know Your Client (KYC), and Finance.\n",
    "\n",
    "Responsibilities\n",
    "- Set up a new IT Vertical involved in IT Application Development and Maintenance and Production Support team for Global Risk and Finance team of Societe Generale Group\n",
    "- Development of applications for Basel III Regulatory Programs (Credit Risk and Liquidity Risk Indicators)\n",
    "- Anti Money Laundering and Counter Terrorism Financing  - Using Java, Oracle  db, and Java Rules Engine (Drools). Then advanced using Hadoop Stack\n",
    "- PeopleSoft Finance Modules\n",
    "- Global Applications with Users across APAC, EMEA and AMER\n",
    "- Started Digital Transformation with applications for Mobility, Social Media, Big Data and Analytics\n",
    "\n",
    "\n",
    "Other experiences going back to the beginning of the carrer can be shared as a detailed Resume \n",
    "\n",
    "\n",
    " \n",
    "Personal Attributes\n",
    "-\tLeader of a happy and motivated team\n",
    "-\tConfident Communicator, Negotiator and Facilitator\n",
    "-\tAttention to detail, Critical Thinking, Flexibility and Resourcefulness\n",
    "-\tAnalytical Thinking and Innovation, Complex Problem Solving\n",
    "-\tPassionate about Learning\n",
    "-\tCommunication skill for presentation to Executive Committee\n",
    "-\tGlobal exposure and Cultural Diversity\n",
    "\n",
    "Business Skills\n",
    "-\tBusiness Stakeholders Relationship Management\n",
    "-\tInfluencing key decision making\n",
    "-\tTeam Mentoring, Coaching and Conflict Resolution\n",
    "\n",
    "Cloud and Machine Learning\n",
    "-\tAzure and AWS Cloud\n",
    "-\tMachine Learning models for classification, regression and clustering using Scikit-learn\n",
    "-\tMachine Learning Neural Networks using TensorFlow with Keras and PyTorch with fastai\n",
    "-\tArtificial Intelligence using Azure and AWS Cognitive Services\n",
    "-\tGenerative AI via Open AI API, LangChain API\n",
    "\n",
    "Certifications\n",
    "·\t2023 – Generative AI for Everyone\n",
    "·\t2023 – Generative AI – ChatGPT Prompt Engineering, Building Systems with ChatGPT API\n",
    "·\t2022 - Microsoft Certified: Azure Data Fundamentals\n",
    "·\t2022 - Microsoft Certified: Azure AI Fundamentals\n",
    "·\t2022 - Microsoft Certified: Azure Fundamentals\n",
    "·\t2022 – Neural Networks and Deep Learning\n",
    "·\t2021 – Python and Machine Learning in Kaggle\n",
    "·\t2021 – Data Governance Fundamentals\n",
    "·\t2020 – AWS Certified: Solutions Architect – Associate\n",
    "·\t2015\t- Hadoop Platform and Application Framework, by University of California, Coursera\n",
    "·\t2015\t- Introduction to Big Data, by University of California, on Coursera\n",
    "·\t2015\t- Data Scientist Toolbox, by Johns Hopkins University on Coursera\n",
    "·\t2009\t - PMI Project Management Professional (PMP) Certified\n",
    "\n",
    "My Startup\n",
    "·\tStart-up to educate kids in STEM, http://letsstem.org/\n",
    "\n",
    "Code and Blog\n",
    "·\tGithub - https://github.com/mahtabsyed \n",
    "·\tKaggle - https://www.kaggle.com/mahtabsyed \n",
    "·\tBlogs on LinkedIn - https://www.linkedin.com/in/mahtabsyed/\n",
    "·\tBlogs on my website – https://mahtabsyedcom.azurewebsites.net\n",
    "\n",
    "Work Authorization - Australian Citizen\n",
    "\n",
    "References - On request\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Name\": \"Mahtab Syed\",\n",
      "    \"Email\": \"mahtab.syed@gmail.com\",\n",
      "    \"Phone\": \"0487031011\",\n",
      "    \"Summary\": \"IT Leader with 20 years’ global experience, delivering complex Technical and Business critical programs\",\n",
      "    \"Skills\": \"IT Strategy, Organizational Strategy, Data Strategy, Data Governance, Transformation, Capability, Leadership, Coaching, Mentoring, People Management, Workforce planning, Hiring, Career Development, Capacity allocation, Performance Management, PMI PMP Certified, AWS Solution Architect Associate, Data Engineering, Business Partner, Key Stakeholder Management, Executive Communication\",\n",
      "    \"Technology\": \"Azure, AWS, Data Engineering, SQL, Python, Pandas, NumPy, matplotlib, Scikit-learn, TensorFlow, PyTorch, Power BI, Tableau, Enterprise Architecture, Full Stack Developer, Master Data Management, Object Oriented Programming, Service Oriented Architecture, Java, .NET Framework, Python, C++, SQL, RDMBS, No SQL Database\",\n",
      "    \"Seniority\": \"20\",\n",
      "    \"AI Knowledge\": \"Yes\",\n",
      "    \"Full stack developer\": \"Yes\",\n",
      "    \"Team Management\": \"Yes\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the Resume text: \n",
    "- Name\n",
    "- Email\n",
    "- Phone remove any white spaces\n",
    "- Summary in less than 20 words\n",
    "- Skills\n",
    "- Technology\n",
    "- Seniority as number of years of experience\n",
    "- AI Knowledge as Yes oer No\n",
    "- Full stack developer as Yes or No\n",
    "- Team Manageemnt as Yes or No\n",
    "\n",
    "The Resume is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Name\", \"Email\", \"Phone\", \"Summary\", \"Skills\", \"Technology\", \"Seniority\" as the keys. \\\n",
    "For multiple values use comma separated values \\\n",
    "Remove hyphen, tab and new line characters \\\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "  \n",
    "Resume text: '''{resume_1}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdesc_1 = \"\"\"\n",
    "UST - AI & Data Architect\n",
    "https://www.linkedin.com/jobs/view/3783447277/\n",
    "About the job\n",
    "Job Description\n",
    "\n",
    "UST is seeking a highly skilled and experienced AI & Data Architect or Lead to join our Technology Services team in Melbourne, Australia. \n",
    "The ideal candidate will have a deep understanding of both artificial intelligence and data architecture, with a proven track record of designing and implementing scalable, efficient, and robust solutions. \n",
    "The role involves leading the development and execution of our organisation's AI and data strategy, ensuring alignment with business goals and industry best practices. \n",
    "This role entails playing a pivotal part in expanding our AI capabilities, so a mix of strategic, and tactical skills is highly desirable.\n",
    "\n",
    "In This Role You Will\n",
    "•\tAI Strategy and Planning: Develop and drive the organisation's AI strategy in collaboration with business leaders.\n",
    "•\tIdentify opportunities for leveraging AI technologies to enhance business processes and decision-making.\n",
    "•\tData Management and Architecture: Design, implement, and maintain a comprehensive data architecture that supports the organization's business objectives.\n",
    "•\tEnsure data integrity, security, and compliance with relevant regulations.\n",
    "•\tMachine Learning and AI Development: Lead the design and implementation of machine learning models and algorithms.\n",
    "•\tCollaborate with data scientists and engineers to deploy AI solutions into production.\n",
    "•\tDeploying AI models and LLMs on GPU instances for real-time applications and decision-making systems, to supporting advanced AI research and development within our public cloud infrastructure with hyperscalers.\n",
    "•\tData Governance: Establish and enforce data governance policies and best practices.\n",
    "•\tDefine data quality standards and ensure adherence throughout the organisation.\n",
    "•\tTechnology Evaluation and Selection: Evaluate and recommend AI and data technologies, tools, and platforms.\n",
    "•\tStay abreast of industry trends and advancements to inform technology decisions.\n",
    "•\tCollaboration and Communication: Collaborate with cross-functional teams, including data scientists, engineers, and business stakeholders.\n",
    "•\tCommunicate complex technical concepts to non-technical stakeholders.\n",
    "•\tLeadership and Team Management: Provide leadership and mentorship to a team of AI and data professionals for Delivery advisory and Pre-Sales.\n",
    "•\tFoster a culture of innovation, collaboration, and continuous learning.\n",
    "\n",
    "To Be Successful In This Role You Will Have\n",
    "•\tBachelor's or Master's degree in Computer Science, Data Science, Engineering or a related field.\n",
    "•\tProven experience (15-20 years) in AI and data architecture roles, with a focus on designing and implementing scalable solutions.\n",
    "•\tSolid background in machine learning with experience in large-scale training and deployment of deep neural nets and/or transformer architectures.\n",
    "•\tUpto 5 years of experience with AI based solutions, Predictive Modeling, Advance Analytics, machine learning based solutions, and semantic search technologies.\n",
    "•\tMinimum 3 years of experience in building, scaling, and optimising training and inferencing systems for deep neural networks.\n",
    "•\tStrong expertise in machine learning, data modelling, and data visualisation.\n",
    "•\tProficiency in programming languages such as Python, R, or Java.\n",
    "•\tExperience with big data technologies (e.g., Hadoop, Spark) and cloud platforms (e.g., AWS, Azure, GCP).\n",
    "•\tExcellent leadership and communication skills.\n",
    "\n",
    "Additional Preferred Skills\n",
    "•\tCertifications in AI, machine learning, or data architecture.\n",
    "•\tExperience with deep learning frameworks (e.g., TensorFlow, PyTorch).\n",
    "•\tKnowledge of natural language processing (NLP) and computer vision.\n",
    "•\tComfortable with GenAI tools and platforms (e.g Duet AI, DallE2, Scribe, Github Copilot, Azure Co-Pilot, Vertex AI, Sagemaker, Azure ML etc.)\n",
    "•\tAbility to navigate fast-paced environments with occasional ambiguity, managing competing priorities and deadlines effectively\n",
    "•\tRapid iteration skills in collaboration with client product teams, and engineers to enhance product experiences while building foundational capabilities.\n",
    "•\tFamiliarity with deploying large neural network models in high-demand production environments.\n",
    "\n",
    "Benefits & Perks\n",
    "•\tFlexible/hybrid working arrangements.\n",
    "•\tHealth insurance.\n",
    "•\tNovated Car Lease.\n",
    "•\tAccess to UST Perks (Reward Gateway), which offers discounts across major retailers.\n",
    "\n",
    "Our commitment to Diversity, Equity and Inclusion\n",
    "\n",
    "Diversity and Inclusion are among the founding blocks of how UST as an organisation translates its values of Humility, Humanity, and Integrity into practice.\n",
    "\n",
    "About UST\n",
    "\n",
    "For more than 23 years, UST has worked side by side with the world's best companies to make a real impact through digital transformation. Together, with over 30,000 employees in 30+ countries, we build for boundless impact—touching billions of lives in the process. Visit us at www.ust.com/au\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Extract key skills and match:\n",
      "\n",
      "Key Skills from Resume:\n",
      "- Data Engineering\n",
      "- Machine Learning\n",
      "- Artificial Intelligence\n",
      "- Azure and AWS Solutions\n",
      "- Data Governance\n",
      "- Leadership of high-performance teams\n",
      "- Agile Scrum and Kanban\n",
      "- Cloud and Machine Learning\n",
      "- Generative AI\n",
      "- IT Strategy\n",
      "- Data Analytics\n",
      "- Enterprise Architecture\n",
      "- Object Oriented Programming\n",
      "- Python, Java, SQL\n",
      "- Data Visualization\n",
      "- Stakeholder Management\n",
      "\n",
      "Key Skills from Job Description:\n",
      "- AI Strategy and Planning\n",
      "- Data Management and Architecture\n",
      "- Machine Learning and AI Development\n",
      "- Data Governance\n",
      "- Technology Evaluation and Selection\n",
      "- Collaboration and Communication\n",
      "- Leadership and Team Management\n",
      "- Strong expertise in machine learning\n",
      "- Proficiency in programming languages such as Python, R, or Java\n",
      "- Experience with big data technologies and cloud platforms\n",
      "- Excellent leadership and communication skills\n",
      "\n",
      "Step 2 - Summarize and match:\n",
      "\n",
      "The candidate's resume showcases a strong background in IT leadership, data engineering, machine learning, artificial intelligence, and cloud technologies, particularly Azure and AWS. They have experience leading high-performance teams, implementing data governance strategies, and working with various programming languages. The candidate also has certifications in AI, machine learning, and data governance.\n",
      "\n",
      "The job description is seeking an AI & Data Architect with expertise in AI strategy, data management, machine learning development, data governance, and technology evaluation. They should have strong leadership and communication skills, proficiency in programming languages like Python, and experience with big data technologies and cloud platforms.\n",
      "\n",
      "Step 3 - Identify key success factors and match:\n",
      "\n",
      "The candidate's extensive experience in IT leadership, data engineering, and machine learning align well with the requirements of the AI & Data Architect role. Their skills in data governance, cloud technologies, and leadership of high-performance teams make them a suitable candidate for leading the development and execution of AI and data strategies within the organization.\n",
      "\n",
      "Overall Match Rating: 90/100 - Excellent Match\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Can you rate how well this Resume in '''{resume_1}''' matches with this Job description in ####{jobdesc_1}#### \\\n",
    "in scale of 1 to 100 where 1 is no match (negative), 50 is ok match (neutral) and 100 is excellent match (positive).\\\n",
    "You can follow these steps:\\\n",
    "Step 1 - Extract key skills and match\\\n",
    "Step 2 - Summarize and match\\\n",
    "Step 3 - Identify key success factors and match\\\n",
    "\n",
    "The Resume is delimited with triple ''' \\\n",
    "The Job Description is delimited with #### \\\n",
    "  \n",
    "Resume text: '''{resume_1}''' \\\n",
    "Job description: ####{jobdesc_1}####  \\\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_2 = \"\"\"\n",
    "\n",
    "Shabana Yasmeen\n",
    "0499 696 176 | Melbourne VIC 3004 | Australian PR | LinkedIn: shabanayasmeen | shabana.yasmeen@nab.com.au\n",
    "Cloud (AWS) | DevOps & Compliance | Service Governance |Data Analyst | Database Developer |Data Warehouse| BI | ETL | Data Replication | Data Migration | Data Integration |\n",
    "Application Support Analyst | SDLC | Customer Service | Predictive Modelling\n",
    "Software Engineer with a Master’s in Computer Applications and 12 years’ experience:\n",
    "• 6 months in DevOps and Compliance\n",
    "• 1.5 years in Service and Governance\n",
    "• 5 years managing data infrastructure, 3 years in data replication and migration, 2 years in data\n",
    "integration and data cleansing\n",
    "EXPERIENCE SUMMARY\n",
    "DEVOPS AND COMPLIANCE\n",
    "• Supporting the operation of services through practical application of DevOps practices to meet NABs SLAs and Service & Governance targets.\n",
    "• Designing and developing ‘infrastructure as code’ to build resources in cloud\n",
    "• Using CI/CD Cloud technology\n",
    "• Promoting AWS and cloud best practices to maximise performance, reliability and resilience while\n",
    "minimising infrastructure costs.\n",
    "• Reducing AWS Billing costs by choosing the right sized resources for our EC2 instances and applying\n",
    "tags that ensure instances are up and running during working hours and cleaning-up unused resources\n",
    "like EC2, RDS\n",
    "• Patching of all EC2 instances Production and Non-Production\n",
    "• Supporting and troubleshooting production and non-production issues\n",
    "• Using productivity and collaboration tools such as JIRA/Rally and Confluence in a software delivery\n",
    "environment\n",
    "SERVICE GOVERNANCE\n",
    "• Achieved CAST attestation in Deputy\n",
    "• Managed Change request in ServiceNab\n",
    "• Managed Disaster Recovery (DR) plan for new application in DRMS\n",
    "• Registration of new application in PlanningIT\n",
    "• Operational Readiness (ORR)\n",
    "DATABASE DEVELOPMENT AND SUPPORT\n",
    "• Software Development | 7 years’ experience in Application Development using Oracle PL/SQL, SQL, Golden Gate, Oracle Apps, Oracle Advanced Queuing in Oracle 9i, 10g, 11i and 12c/Data warehouse (EDW/ODS)\n",
    "• Agile DevOps | Worked in DevOps environments, designed and supported 24x7 production applications, performance tuning, space management, configuration management, high availability and troubleshooting.\n",
    "• Production Support | Managed 24x7 production databases, provided support to over 50 Prod, Dev and Test databases in Oracle 9i, 10g, 11i and 12c with volumes up to 10 TB.\n",
    "• Testing | Participated in integration testing and UAT. Fixed the code when bugs were raised during testing.\n",
    "Private & Confidential Page 1 of 5\n",
    "    \n",
    "Shabana Yasmeen\n",
    " \n",
    "APPLICATION DESIGN AND ANALYSIS\n",
    "• SDLC | Excellent knowledge of Software Development Life Cycle (SDLC). Used Waterfall and Agile methodologies.\n",
    "• Functional Specifications | Analysed Functional Requirements Documents, System Requirements Specifications and Business Requirements Documents.\n",
    "• Business Process Modelling | Designed and documented Business processes through Use Cases and workshops. Involved in creating, analysing and defining detailed “As Is” and “To Be”.\n",
    "• Technical Specifications | Adept at determining technical specs based on Requirement Specifications, Functional Specifications and Design Specifications.\n",
    "DATA ENGINEERING\n",
    "• Data Engineering | 5 years developing and managing the infrastructure supporting large scale data for database/data warehouse (EDW/ODS)\n",
    "• Data Modelling | 3 years’ experience in the techniques and preparation of ER diagram, Conceptual Data Model, Logical Data Model and Physical Data Model.\n",
    "• Data Migration | Experience across two Data Migration projects in Finance, Healthcare Enterprise.\n",
    "• Data Analysis & Cleansing | Involved in analysing complex data, data cleaning and data\n",
    "synchronisation using customized PL/SQL, Golden Gate scripts for database/data warehouse.\n",
    "TECHNICAL SKILLS\n",
    " \n",
    "DATABASE/OS\n",
    "• Oracle 9i,10g,11g,12c, SQL Server\n",
    "• SQL Loader • Linux\n",
    "• Windows\n",
    "ETL/BUSINESS INTELLIGENCE\n",
    "• Kettle Pentaho Data Integration\n",
    "• Informatica, SSIS, SSRS\n",
    "• MicroStrategy SAP BO, Tableau\n",
    "• EDW (Enterprise Data Warehouse)\n",
    "LANGUAGES\n",
    "• PL/SQL, SQL, Shell Scripting,\n",
    "REPLICATION TOOL/WEB TOOL\n",
    "• Golden Gate • Toad\n",
    "• Remedy\n",
    "• ServiceNow\n",
    "Cloud\n",
    "• AWS\n",
    "• Azure CI/CD\n",
    "• Jenkins\n",
    "Monitoring tool\n",
    "• Splunk\n",
    "• AppDynamics ERP/CRM\n",
    "• Oracle E Business Suite • Siebel\n",
    "SCHEDULER/VERSION CONTROL\n",
    "• Appworx\n",
    "• Autosys\n",
    "• Dollar Universe\n",
    "• Tidal\n",
    "• PVCS, Git\n",
    "• ClearCase\n",
    "Collaboration tools\n",
    "• JIRA\n",
    "• Rally\n",
    "• Confluence\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Name\": \"Shabana Yasmeen\",\n",
      "    \"Email\": \"shabana.yasmeen@nab.com.au\",\n",
      "    \"Phone\": \"0499696176\",\n",
      "    \"Summary\": \"Software Engineer with 12 years' experience in Cloud, DevOps, Data Analyst, and Database Development.\",\n",
      "    \"Skills\": \"Data Analyst, Database Developer, Data Warehouse, BI, ETL, Data Replication, Data Migration, Data Integration, Application Support Analyst, SDLC, Customer Service, Predictive Modelling\",\n",
      "    \"Technology\": \"Oracle 9i, 10g, 11g, 12c, SQL Server, Kettle Pentaho Data Integration, Informatica, SSIS, SSRS, MicroStrategy, SAP BO, Tableau, Golden Gate, Toad, Remedy, ServiceNow, AWS, Azure, Jenkins, Splunk, AppDynamics, Oracle E Business Suite, Siebel, Appworx, Autosys, Dollar Universe, Tidal, PVCS, Git, ClearCase, JIRA, Rally, Confluence\",\n",
      "    \"Seniority\": \"12\",\n",
      "    \"AI Knowledge\": \"unknown\",\n",
      "    \"Full stack developer\": \"unknown\",\n",
      "    \"Team Management\": \"unknown\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the Resume text: \n",
    "- Name\n",
    "- Email\n",
    "- Phone remove any white spaces\n",
    "- Summary in less than 20 words\n",
    "- Skills\n",
    "- Technology\n",
    "- Seniority as number of years of experience\n",
    "- AI Knowledge as Yes oer No\n",
    "- Full stack developer as Yes or No\n",
    "- Team Manageemnt as Yes or No\n",
    "\n",
    "The Resume is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Name\", \"Email\", \"Phone\", \"Summary\", \"Skills\", \"Technology\", \"Seniority\" as the keys. \\\n",
    "For multiple values use comma separated values \\\n",
    "Remove hyphen, tab and new line characters \\\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "  \n",
    "Resume text: '''{resume_2}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate the match between the Resume and the Job Description as a 60 out of 100. While the Resume showcases relevant experience in areas such as DevOps, Compliance, Data Engineering, and Database Development, it lacks specific experience in AI, machine learning, and deep learning frameworks that are required for the AI & Data Architect role. Additionally, the Job Description emphasizes the need for extensive experience in AI and data architecture roles, which the Resume does not fully align with. However, there are some transferable skills and technical knowledge that could be beneficial for the role, hence the neutral rating.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Can you rate how well this Resume in '''{resume_2}''' matches with this Job description in ####{jobdesc_1}#### \\\n",
    "in scale of 1 to 100 where 1 is no match (negative), 50 is ok match (neutral) and 100 is excellent match (positive).\\\n",
    "\n",
    "The Resume is delimited with triple ''' \\\n",
    "The Job Description is delimited with #### \\\n",
    "\n",
    "Resume text: '''{resume_2}''' \\\n",
    "Job description: ####{jobdesc_1}####  \\\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
